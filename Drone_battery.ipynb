{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drone_battery.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGbEG9cGvESCEE5c0rC5te",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnirudhSreeram/MBSE_AI_SE/blob/master/Drone_battery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c25OZvn_Rkm"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "#from network import Net\n",
        "\n",
        "\n",
        "dataset = pd.read_csv('data_gathered.csv')\n",
        "print(dataset)\n",
        "print(dataset.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfnV7F2HA-n8"
      },
      "source": [
        "dataset.dropna(subset = [\"x_value\"], inplace=True)\n",
        "print(dataset)\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWEr9Ha_Fuid"
      },
      "source": [
        "#dataset['Target'].replace(encode_map, inplace=True)\n",
        "#print(dataset)\n",
        "X = dataset.drop('Target',axis=1).astype(float)\n",
        "Y = dataset['Target']\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(X)\n",
        "print(Y)\n",
        "#X = dataset.iloc[:, :].values\n",
        "#Y = dataset.iloc[:].values\n",
        "#print(X.shape)\n",
        "#print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtzi6HTZHJAP"
      },
      "source": [
        "# split the training data\n",
        "classes = ('1.0', '0.0')\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "data = (X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhSOHrd-Hw87"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(13, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.s = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.s(self.fc3(x))\n",
        "        return x"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNO1PYIbH_CL"
      },
      "source": [
        "### code to generate the data loaders\n",
        "## train data\n",
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(X_train.to_numpy()), \n",
        "                       torch.FloatTensor(Y_train.to_numpy()))\n",
        "## test data    \n",
        "class testData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "test_data = testData(torch.FloatTensor(X_test.to_numpy()))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fHN0LdpWAHya",
        "outputId": "0bc547b1-92b5-4412-9e49-ad9ceb76ba0f"
      },
      "source": [
        "\n",
        "EPOCHS = 150\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.001\n",
        "wd = 0.1\n",
        "net = Net()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "#optimizer = optim.Adam(net.parameters(), LEARNING_RATE, weight_decay=wd)\n",
        "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "print(pytorch_total_params)\n",
        "\n",
        "#set the loaders\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(dataset=test_data, batch_size=1)\n",
        "\n",
        "\n",
        "## function for accuracy calculation\n",
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "    y_test = torch.round(y_pred)\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = acc * 100\n",
        "    return acc\n",
        "\n",
        "### setting the model to train\n",
        "net.train()\n",
        "acc_1 = []\n",
        "def train() :    \n",
        "  for e in range(1, EPOCHS+1):\n",
        "      epoch_loss = 0\n",
        "      epoch_acc = 0\n",
        "      for i, data in enumerate(train_loader,0):\n",
        "          X_batch, y_batch = data\n",
        "          optimizer.zero_grad()\n",
        "          X_batch = torch.flatten(X_batch)\n",
        "          #print(X_batch.shape)\n",
        "          #print(y_batch.shape)\n",
        "          y_pred = net(Variable(X_batch.float()))\n",
        "          #y_batch = torch.unsqueeze(y_batch, 1) \n",
        "          loss = criterion(y_pred,Variable(y_batch.float())) \n",
        "          acc = binary_acc(y_pred, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          epoch_loss += loss.item()\n",
        "          epoch_acc += acc.item()\n",
        "      print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
        "      acc_1.append(epoch_acc/len(train_loader))      \n",
        "\n",
        "train()\n",
        "\n",
        "plt.plot(acc_1, 'r--')\n",
        "plt.ylabel('CV Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10113\n",
            "Epoch 001: | Loss: 0.67899 | Acc: 21.429\n",
            "Epoch 002: | Loss: 0.67648 | Acc: 46.429\n",
            "Epoch 003: | Loss: 0.67313 | Acc: 28.571\n",
            "Epoch 004: | Loss: 0.66388 | Acc: 10.714\n",
            "Epoch 005: | Loss: 0.66373 | Acc: 10.714\n",
            "Epoch 006: | Loss: 0.66367 | Acc: 10.714\n",
            "Epoch 007: | Loss: 0.66362 | Acc: 10.714\n",
            "Epoch 008: | Loss: 0.66359 | Acc: 10.714\n",
            "Epoch 009: | Loss: 0.66354 | Acc: 10.714\n",
            "Epoch 010: | Loss: 0.66350 | Acc: 10.714\n",
            "Epoch 011: | Loss: 0.66346 | Acc: 10.714\n",
            "Epoch 012: | Loss: 0.66341 | Acc: 10.714\n",
            "Epoch 013: | Loss: 0.66336 | Acc: 10.714\n",
            "Epoch 014: | Loss: 0.66328 | Acc: 10.714\n",
            "Epoch 015: | Loss: 0.66316 | Acc: 10.714\n",
            "Epoch 016: | Loss: 0.66276 | Acc: 10.714\n",
            "Epoch 017: | Loss: 0.62230 | Acc: 21.429\n",
            "Epoch 018: | Loss: 0.49773 | Acc: 57.143\n",
            "Epoch 019: | Loss: 0.47724 | Acc: 60.714\n",
            "Epoch 020: | Loss: 0.50321 | Acc: 53.571\n",
            "Epoch 021: | Loss: 0.47663 | Acc: 60.714\n",
            "Epoch 022: | Loss: 0.47967 | Acc: 64.286\n",
            "Epoch 023: | Loss: 0.53318 | Acc: 60.714\n",
            "Epoch 024: | Loss: 0.49386 | Acc: 64.286\n",
            "Epoch 025: | Loss: 0.49938 | Acc: 60.714\n",
            "Epoch 026: | Loss: 0.48547 | Acc: 57.143\n",
            "Epoch 027: | Loss: 0.47334 | Acc: 60.714\n",
            "Epoch 028: | Loss: 0.47319 | Acc: 60.714\n",
            "Epoch 029: | Loss: 0.47326 | Acc: 60.714\n",
            "Epoch 030: | Loss: 0.47372 | Acc: 60.714\n",
            "Epoch 031: | Loss: 0.47364 | Acc: 60.714\n",
            "Epoch 032: | Loss: 0.47302 | Acc: 60.714\n",
            "Epoch 033: | Loss: 0.47328 | Acc: 60.714\n",
            "Epoch 034: | Loss: 0.47329 | Acc: 60.714\n",
            "Epoch 035: | Loss: 0.47296 | Acc: 60.714\n",
            "Epoch 036: | Loss: 0.47300 | Acc: 60.714\n",
            "Epoch 037: | Loss: 0.47303 | Acc: 60.714\n",
            "Epoch 038: | Loss: 0.47311 | Acc: 60.714\n",
            "Epoch 039: | Loss: 0.47294 | Acc: 60.714\n",
            "Epoch 040: | Loss: 0.47284 | Acc: 60.714\n",
            "Epoch 041: | Loss: 0.47286 | Acc: 60.714\n",
            "Epoch 042: | Loss: 0.47294 | Acc: 60.714\n",
            "Epoch 043: | Loss: 0.47277 | Acc: 60.714\n",
            "Epoch 044: | Loss: 0.47268 | Acc: 60.714\n",
            "Epoch 045: | Loss: 0.47281 | Acc: 60.714\n",
            "Epoch 046: | Loss: 0.47270 | Acc: 60.714\n",
            "Epoch 047: | Loss: 0.47280 | Acc: 60.714\n",
            "Epoch 048: | Loss: 0.47256 | Acc: 60.714\n",
            "Epoch 049: | Loss: 0.47256 | Acc: 60.714\n",
            "Epoch 050: | Loss: 0.47256 | Acc: 60.714\n",
            "Epoch 051: | Loss: 0.47249 | Acc: 60.714\n",
            "Epoch 052: | Loss: 0.47254 | Acc: 60.714\n",
            "Epoch 053: | Loss: 0.47247 | Acc: 60.714\n",
            "Epoch 054: | Loss: 0.47240 | Acc: 60.714\n",
            "Epoch 055: | Loss: 0.47243 | Acc: 60.714\n",
            "Epoch 056: | Loss: 0.47241 | Acc: 60.714\n",
            "Epoch 057: | Loss: 0.47230 | Acc: 60.714\n",
            "Epoch 058: | Loss: 0.47236 | Acc: 60.714\n",
            "Epoch 059: | Loss: 0.47236 | Acc: 60.714\n",
            "Epoch 060: | Loss: 0.47223 | Acc: 60.714\n",
            "Epoch 061: | Loss: 0.47234 | Acc: 60.714\n",
            "Epoch 062: | Loss: 0.47221 | Acc: 60.714\n",
            "Epoch 063: | Loss: 0.47216 | Acc: 60.714\n",
            "Epoch 064: | Loss: 0.47217 | Acc: 60.714\n",
            "Epoch 065: | Loss: 0.47212 | Acc: 60.714\n",
            "Epoch 066: | Loss: 0.47211 | Acc: 60.714\n",
            "Epoch 067: | Loss: 0.47215 | Acc: 60.714\n",
            "Epoch 068: | Loss: 0.47208 | Acc: 60.714\n",
            "Epoch 069: | Loss: 0.47199 | Acc: 60.714\n",
            "Epoch 070: | Loss: 0.47199 | Acc: 60.714\n",
            "Epoch 071: | Loss: 0.47200 | Acc: 60.714\n",
            "Epoch 072: | Loss: 0.47198 | Acc: 60.714\n",
            "Epoch 073: | Loss: 0.47190 | Acc: 60.714\n",
            "Epoch 074: | Loss: 0.47188 | Acc: 60.714\n",
            "Epoch 075: | Loss: 0.47187 | Acc: 60.714\n",
            "Epoch 076: | Loss: 0.47183 | Acc: 60.714\n",
            "Epoch 077: | Loss: 0.47186 | Acc: 60.714\n",
            "Epoch 078: | Loss: 0.47179 | Acc: 60.714\n",
            "Epoch 079: | Loss: 0.47183 | Acc: 60.714\n",
            "Epoch 080: | Loss: 0.47174 | Acc: 60.714\n",
            "Epoch 081: | Loss: 0.47168 | Acc: 60.714\n",
            "Epoch 082: | Loss: 0.47174 | Acc: 60.714\n",
            "Epoch 083: | Loss: 0.47162 | Acc: 60.714\n",
            "Epoch 084: | Loss: 0.47165 | Acc: 60.714\n",
            "Epoch 085: | Loss: 0.47161 | Acc: 60.714\n",
            "Epoch 086: | Loss: 0.47161 | Acc: 60.714\n",
            "Epoch 087: | Loss: 0.47154 | Acc: 60.714\n",
            "Epoch 088: | Loss: 0.47152 | Acc: 60.714\n",
            "Epoch 089: | Loss: 0.47152 | Acc: 60.714\n",
            "Epoch 090: | Loss: 0.47147 | Acc: 60.714\n",
            "Epoch 091: | Loss: 0.47145 | Acc: 60.714\n",
            "Epoch 092: | Loss: 0.47148 | Acc: 60.714\n",
            "Epoch 093: | Loss: 0.47138 | Acc: 60.714\n",
            "Epoch 094: | Loss: 0.47135 | Acc: 60.714\n",
            "Epoch 095: | Loss: 0.47134 | Acc: 60.714\n",
            "Epoch 096: | Loss: 0.47130 | Acc: 60.714\n",
            "Epoch 097: | Loss: 0.47130 | Acc: 60.714\n",
            "Epoch 098: | Loss: 0.47134 | Acc: 60.714\n",
            "Epoch 099: | Loss: 0.47125 | Acc: 60.714\n",
            "Epoch 100: | Loss: 0.47125 | Acc: 60.714\n",
            "Epoch 101: | Loss: 0.47120 | Acc: 60.714\n",
            "Epoch 102: | Loss: 0.47119 | Acc: 60.714\n",
            "Epoch 103: | Loss: 0.47116 | Acc: 60.714\n",
            "Epoch 104: | Loss: 0.47112 | Acc: 60.714\n",
            "Epoch 105: | Loss: 0.47110 | Acc: 60.714\n",
            "Epoch 106: | Loss: 0.47109 | Acc: 60.714\n",
            "Epoch 107: | Loss: 0.47103 | Acc: 60.714\n",
            "Epoch 108: | Loss: 0.47101 | Acc: 60.714\n",
            "Epoch 109: | Loss: 0.47097 | Acc: 60.714\n",
            "Epoch 110: | Loss: 0.47097 | Acc: 60.714\n",
            "Epoch 111: | Loss: 0.47094 | Acc: 60.714\n",
            "Epoch 112: | Loss: 0.47094 | Acc: 60.714\n",
            "Epoch 113: | Loss: 0.47095 | Acc: 60.714\n",
            "Epoch 114: | Loss: 0.47088 | Acc: 60.714\n",
            "Epoch 115: | Loss: 0.47083 | Acc: 60.714\n",
            "Epoch 116: | Loss: 0.47081 | Acc: 60.714\n",
            "Epoch 117: | Loss: 0.47084 | Acc: 60.714\n",
            "Epoch 118: | Loss: 0.47077 | Acc: 60.714\n",
            "Epoch 119: | Loss: 0.47078 | Acc: 60.714\n",
            "Epoch 120: | Loss: 0.47071 | Acc: 60.714\n",
            "Epoch 121: | Loss: 0.47070 | Acc: 60.714\n",
            "Epoch 122: | Loss: 0.47068 | Acc: 60.714\n",
            "Epoch 123: | Loss: 0.47070 | Acc: 60.714\n",
            "Epoch 124: | Loss: 0.47063 | Acc: 60.714\n",
            "Epoch 125: | Loss: 0.47061 | Acc: 60.714\n",
            "Epoch 126: | Loss: 0.47057 | Acc: 60.714\n",
            "Epoch 127: | Loss: 0.47054 | Acc: 60.714\n",
            "Epoch 128: | Loss: 0.47053 | Acc: 60.714\n",
            "Epoch 129: | Loss: 0.47053 | Acc: 60.714\n",
            "Epoch 130: | Loss: 0.47047 | Acc: 60.714\n",
            "Epoch 131: | Loss: 0.47047 | Acc: 60.714\n",
            "Epoch 132: | Loss: 0.47044 | Acc: 60.714\n",
            "Epoch 133: | Loss: 0.47042 | Acc: 60.714\n",
            "Epoch 134: | Loss: 0.47039 | Acc: 60.714\n",
            "Epoch 135: | Loss: 0.47037 | Acc: 60.714\n",
            "Epoch 136: | Loss: 0.47038 | Acc: 60.714\n",
            "Epoch 137: | Loss: 0.47031 | Acc: 60.714\n",
            "Epoch 138: | Loss: 0.47029 | Acc: 60.714\n",
            "Epoch 139: | Loss: 0.47027 | Acc: 60.714\n",
            "Epoch 140: | Loss: 0.47024 | Acc: 60.714\n",
            "Epoch 141: | Loss: 0.47023 | Acc: 60.714\n",
            "Epoch 142: | Loss: 0.47024 | Acc: 60.714\n",
            "Epoch 143: | Loss: 0.47017 | Acc: 60.714\n",
            "Epoch 144: | Loss: 0.47015 | Acc: 60.714\n",
            "Epoch 145: | Loss: 0.47012 | Acc: 60.714\n",
            "Epoch 146: | Loss: 0.47012 | Acc: 60.714\n",
            "Epoch 147: | Loss: 0.47007 | Acc: 60.714\n",
            "Epoch 148: | Loss: 0.47010 | Acc: 60.714\n",
            "Epoch 149: | Loss: 0.47005 | Acc: 60.714\n",
            "Epoch 150: | Loss: 0.47001 | Acc: 60.714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRU1bn38e/DDArSCCKDCIpgAA1iJ85GwDlG1GjU+BpijNybaKImGocYXSauXHNNNJrBxJgoUaNG1IsSY0AccW4UBYUWI6jIrCCDzDzvH/tUqumu7i6gz9BVv89atarO2VW1Hw5dT+3ae599zN0REZHy0SLtAEREJFlK/CIiZUaJX0SkzCjxi4iUGSV+EZEy0yrtAIrRtWtX79u3b9phiIg0K1OnTl3q7t1q728Wib9v375UVVWlHYaISLNiZu8X2q+uHhGRMqPELyJSZpT4RUTKjBK/iEiZUeIXESkzSvwiImVGiV9EpMwo8WdVVRW8+GLaUYhICWoWJ3CVpS98Idzregki0sTU4s+CtWthp53g0EPrlm3alHw8IlLSlPiz4N13YcUKeP55WLky7Lv99nD/fsEzrkVEtpkSfxZUV9d9vPfe4X7WrOTjEZGSpj7+LKiZ3Kur4Y034MorYdw4OOyw9OISkZKkxJ8Fs2ZB9+6wdGl4/Nlnocvn5JOhhX6UiUjTUlbJgh12gOHDYY89Qp/+rFkwYAA88wyMHZt2dCJSYsybwXTByspKL4v1+FesgI4dYa+9YP/9w+MJE2DhwrQjE5FmyMymuntl7f1q8WdJp06wbh3MmRMGdwcOhEWLYNmytCMTkRKixJ+2556DffeF6dNh2jQ45RQ49lg4/PD8zJ6as35ERLaTEn/aZswISb+iAlatgn/+E84/H0aODC1+0JROEWlSSvxpmzUrDO726pVv4b/9drjv1w9at4Z33kkvPhEpOZrOmbTq6jB1s3Pn/PbAgWAGXbuGfZdeCpdcEpL+v/8NPXvmX790aZjtkxuUb9MGTjwxPH7hBZg/f8v6OnSA448Pj599FhYv3rJ8p53gqKPC4yefhE8+2bJ8553DjCOAiRPDAHRN3bvnzzV47LEwFbWmXr3goIPC4/HjYcOGLct33z2/LtGDD9Zdm6h/fxg6NCxd8fDD1LH33jBkSBgbefTRuuVDhoTnrF4dfk3VNnRoqGP5cnjiibrllZXQt2847k8/Xbf8oIPCv3HhQpgypW75YYeFYzRvHrz0Ut3y4cPDMZ47NyzMV9tRR4X/o9mzw/kdtR13XGg4zJwJb71Vt/zEE8PfyPTphbsMTzklTBl+/fXwt1ZTixahHODVV+ueRa6/vWT+9uLg7rHdgM7AOGAWMBM4COgCTAJmR/cVjb3P/vvv7yVh0yZ3cD/ggPy+Pfd0P/30/Hbnzu677Vb/e5x3XniP3G3nnfNlJ5+8ZRm49+2bLz/yyLrl++yTLz/wwLrlBx+cLx88uG750Ufny/v0qVv+1a/myysq6pZ/85v58lat6pZ/73uhbO3aumXgfuWVoXzJksLlP/95KH/vvcLlv/lNKH/jjcLld94ZyqdMKVz+4IOh/PHHC5dPnBjKH3igcPkLL4Tyv/ylcPn06aH85psLl8+dG8qvu65w+ccfh/LLLy9cvn59KD///Lplbdrk/2++8Y265frbS+ZvbzsAVe51c2qs0znNbCzwnLvfbmZtgA7AlcAn7n69mV0eJf7LGnqfkpnO+cEHoZXRpk1oJQCcc06YunnBBWH7s89C6799+7A9ZQrcfTf85jfhF8DBB4c/iz/9KZS3bAmf+1z+/Wu3ilq3zo8VzJkTWh81tW0bpo9CaPGtWbNleYcO4fwCCK3OXNw5O+6Yb5VUV9dtVXXqBH36hMczZ9ZddK5zZ+jdOzyeMYM6unQJv3g2b853gdXUrVto+W3cWHgspHv38Jz16wt3mfXoEVqWa9eGNZNq69UrjL+sXh2OX2277RZaritXFl5XqW/fcIw+/RQ+/LBu+R57hGO8bBl89FHd8v79oV07+PhjWLCgbvmAAeHvafHiui1qCC3OVq3CL5KlS+uWDx4c/t7mz6/b4jYL5RB+sSxfvmW5/vaS+dvbDvVN54wt8ZvZTsA0YA+vUYmZVQNHuPsCM+sBPO3uAxt6r5JJ/BMnwjHHwFNPwRFHFPeasWPhm98Mf9gDBoQP2KpVMGhQnJGKSAlIYx5/P2AJcIeZvW5mt5vZDkB3d881XRYC3Qu92MzGmFmVmVUtWbIkxjATVHsBtmLUntnTp4+SvohslzgTfytgGHCru+8HrAYur/mE6JdAwZ8c7n6bu1e6e2W3bt1iDDNBhx0WfrpfemnYfuut8FPuscfqf03NxP/OO/CrX0GpfBGKSCriTPzzgHnu/nK0PY7wRbAo6uIhui/QMVmihg6FUaPyMwSWLAn9prn+/EIqKkJfYXV1mM1zySV1+0pFRLZCbInf3RcCH5pZrv9+JPA28AgwOto3GhgfVwyZ89xz4X716jCQlRts23nnhl83aFAYHKyuDgN9uQErEZFtEPc8/u8B90Qzet4DziF82fzdzM4F3ge+FnMM2bByZViGoV+/sP3xx/nEn5u/X58nnghzqk84IXT9aKlmEdkOsSZ+d58G1BlRJrT+y0tuYPfQQ8PUtqVLi2/x5xL9rFnhpA4Rke2gpmNScol/+PAwLXPDhnBm37e+FeYzN2TWLDj66DDXeWCDM19FRBqlJRuSMmtWOOHl618PJ21BOF38pJMaf22bNjBpEvz2t/CNb8Qbp4iUPLX4k1JdHc5CrNm6r32mYX123z28bu7ccHEWEZHtoMSflKuvhj/+MSy3MGIE3HprWECqmBZ/y5bhdPVf/jKcPi4ish3U1ZOUIUPyj6dNC1M0P/64+LNwKyrCei6a0SMi20lZJAnucN99+WVzu3bNz+ppbEZPzsyZuhKXiDQJJf4kbN4MZ54JDz0Utrt2DSsxrlrV+Bz+nO7dw2wgEZHtpMSfhI0bw32rqGeta9f8Mq3FJn4RkSaiPv4k1E78++0X1t2vrAxr8YuIJEiJPwm1E/+116YXi4iUPXX1JKF24oewUNvy5WHgV0QkQUr8SejUCV55BU47LWw/+mi4bFxFReHL5YmIxEhdPUlo3Tosz5BT8ySsLl2Sj0dEyppa/ElYuTJcHH327LBdcyZP69bpxCQiZUuJPwmLF8OYMfDSS2FbUzhFJEVK/EmoPbhb7Nm6IiIxUOJPQu3EX1ER7keNSiceESlrGtxNQu3E37KlpnGKSGrU4k9CoXn8IiIpUSZKwuDBYXXNXr3SjkRERIk/Ee3awd57px2FiAigrp5kfPgh3HhjuBcRSZkSfxJmz4Yf/hDmzEk7EhERJf5EaHBXRDJEiT8JSvwikiFK/ElQ4heRDFHiT4ISv4hkiDJREo47Lszo2WWXtCMREYk38ZvZXGAlsAnY6O6VZtYFuB/oC8wFvubuy+KMI3Xt20Pv3mlHISICJNPVM9zdh7p7ZbR9OTDZ3fcCJkfbpW3aNPjpT8OlFkVEUpZGH/8oYGz0eCxwUgoxJOu11+Caa2DFirQjERGJPfE7MNHMpprZmGhfd3dfED1eCHQv9EIzG2NmVWZWtWTJkpjDjJkGd0UkQ+LORIe6+0dmtgswycxm1Sx0dzezgusTu/ttwG0AlZWVzXsNYyV+EcmQWFv87v5RdL8YeBj4IrDIzHoARPeL44whE5T4RSRDYkv8ZraDmXXMPQaOBmYAjwCjo6eNBsbHFUNmKPGLSIbE2eLvDkwxszeAV4B/uPvjwPXAUWY2Gzgy2i5tF1wQZvR07Jh2JCIi8fXxu/t7wOcL7P8YGBlXvZnUpk24iYhkgJZsSMLEiXDppbrOrohkghJ/EqZMgV/9CszSjkRERIk/ERs3amBXRDJDiT8JSvwikiFK/ElQ4heRDFHiT4ISv4hkSHkk/uefh4ceSq/+m2+G5r7ekIiUjPJohh56aLhPazqlGbRsmU7dIiK1lEeL/ytfgf32S6/+O++EK69Mr34RkRrKI/GvXw+tW6dX/5NPwn33pVe/iEgNjXb1mNk+7j49iWBi869/pVu/BndFJEOKafH/3sxeMbPvmtlOsUdUipT4RSRDGk387n4YcBawGzDVzP5mZkfFHllTuuaacJ/W4K4Sv4hkSFF9/O4+G7gKuAz4EnCLmc0ys1PiDK7JtGsX7tetS6f+1q1hhx3SqVtEpJZi+vj3Bc4BvgxMAr7i7q+ZWU/gRSDFCfJFuuqqcL92bf5LIEn33598nSIi9Sim/+E3wO3Ale6+JrfT3eeb2VWxRdaUNm3a8l5EpIwVk/i/DKxx900AZtYCaOfun7n7XbFG11R23x2+9CXYeed06v/Zz8JJXFc1j+9JESltxfTxPwG0r7HdIdrXfGzYkO4VsCZNCnP5RUQyoJjE387dV+U2oscd4gspBvPnw+23w6xZ6dSvWT0ikiHFJP7VZjYst2Fm+wNrGnh+di1fnk69SvwikiHFZKOLgAfMbD5gwK7A6bFG1dSefBJGjAizetKgxC8iGdJoNnL3V81sb2BgtKva3TfEG1YTy03hTCvxV1RAly7p1C0iUkuxzdCBwCCgHTDMzHD3v8YXVhPavBm++tXwOK3EP3lyOvWKiBRQzAlc1wBHEBL/Y8BxwBSgeST+DRtgwYLweCctNSQiUszg7qnASGChu58DfB5oPhl0/fpwf8MNMHx4OjF8+9tw003p1C0iUksxXT1r3H2zmW00s07AYsKCbc1DLvGnPY9fZw2LSEYUk/irzKwz8CdgKrCKsEZP87AhGoe+8ELo2BHOOSf5GDSrR0QypMFsZGYG/I+7Lwf+YGaPA53c/c1EomsK7tCnD3zwASxenE4MSvwikiEN9vG7uxMGdHPbc7c26ZtZSzN73cwmRNv9zOxlM3vXzO43s3j7YHr0gDlzwmPN4xcRKWpw9zUz+8J21HEhMLPG9i+Am9y9P7AMOHc73rs4LVqEPv60En/fvtC9ezp1i4jUUkziPwB40cz+bWZvmtl0Myuq1W9mvQmre94ebRswAhgXPWUscNLWh70VZs8OK3OuX59e4p86VStzikhmFNP/cMx2vP+vgR8BHaPtnYHl7r4x2p4H9Cr0QjMbA4wB6NOnz7ZHsHw5PPtsGNgdOLDx54uIlLhiWvxez61BZnYCsNjdp25LYO5+m7tXuntlt27dtuUtgtysnnHj4L//e9vfZ3sccQTccUc6dYuI1FJMi/8fhERvhCUb+gHVwOBGXncIcKKZHR+9rhNwM9DZzFpFrf7ewEfbGHtx0p7Hv3kzPPNMeiePiYjU0miL3933cfd9o/u9gC9SxDx+d7/C3Xu7e1/gDOBJdz8LeIpwNjDAaGD8NkdfjFziP+EEGD061qoKyp24pVk9IpIRxXT1bMHdXyMM+G6ry4AfmNm7hD7/P2/HezVuxx1h//3DfP405vFvjIYzlPhFJCOKWaTtBzU2WwDDgPlbU4m7Pw08HT1+j/CrIRkHHwxVVXD44enM6lHiF5GMKSYbdazxeCOhz//BeMKJUbt2sHJl8vW6w7BhsOuuydctIlJAMRdiuTaJQGIzYQJcc01IwN7oZKSm16lTmMcvIpIRjfbxm9mkaJG23HaFmf0r3rCa0OLF8Npr4SSuY7bnlAQRkdJQzOBut2iRNgDcfRmwS3whNbHcrJ7LLoPrr0++/oULw+Dy+HgnL4mIFKuYxL/JzP5z6qyZ7U4RJ3BlRi7xt26dTv1r1oRfHMuXN/5cEZEEFJP4fwxMMbO7zOxu4FnginjDakK5xP+Tn0DPnsnXr1k9IpIxxQzuPm5mw4ADo10XufvSeMNqQr16hf791q3TaXUr8YtIxhQzuHsysMHdJ7j7BGCjmcW7omZTOvNMePrpcKH1tWuTn9mTS/wtWyZbr4hIPYrp6rnG3T/NbUQDvdfEF1JM2rULST+3aFtS2rcPvzh2aT7j4SJS2opJ/IWe03z6La6/HvbdNyR+SP7s3f79wy+Oww9Ptl4RkXoUk/irzOxGM9szut1EuOh687BwIbz/PgwdCt/5Trgal4hIGSsmC34PWA/cH93WAN+NM6gmtWFDWJJ5xAj4/e/Dom1JevVVGDAAXmx0QVMRkUQUM6tnNXB5bjua038+cEOMcTWd9evza/Fv2gRmybb6V60Kl3/MTSsVEUlZURnQzLqZ2XfN7DnCevrN58rh69eHqZwPPRSmVM6YkWz9ms4pIhlTbzYys47AKcDXgQHAQ0A/d++dUGxNY+hQaNs23CD5wV0lfhHJmIay0WLgFeAqYIq7ezSnv3m5+OJwP3lyuFfiF5Ey11BXzxVAW+D3wBVmtmcyIcUkremc3brBl78MnTs3/lwRkQTUm/jd/dfufiAwKtr1f0BPM7vMzAYkEl1TOOMMOP74fOJfty7Z+g88MFwTYM/m/b0pIqWjmIutv+fuP3f3fYBKoBPwWOyRNZUlS2DFCujRAy65BPr1SzsiEZFUbdW8Rnef4e4/dvf+cQXU5HLTOXv2hBtugCFDkq1/3LhQ99y5ydYrIlKP0j+NNXcCl3to+Sfdx79qFSxYkGydIiINKP3En2vxf/JJWKHzT39Ktn7N6hGRjKk38ZvZpWbWvObsF3LssTB8eHqzepT4RSRjGspGPYEXzWwucC/wgLsvSSSqpvTzn4f7XAJW4heRMtfQdM6LgT6EE7j2Ad40s8fNbHR0Vm/z0qpVuKWxLPMZZ+R/cYiIpKzBPn4PnnH37wC9gZuAi4BFSQTXJPbcE84/Pzxu2zb5xH/ssXDvvcmvCioiUo+i+h/MbB/gDOB0YCnN6WLrK1fmL7d49dVh7R4RkTLW0CJtewFnEpL9JuA+4Gh3fy+h2JpGbnVOgB/9KPn6f/ELuO46WLZM/fwikgkNZaLHCYO6p7v7Vq9lbGbtgGcJ6/20Asa5+zVm1o/wJbIz4UpeZ7t7fIvV11yPf9GisB5/kte/XbMmzOXXxdZFJCMa6uM/Fni8dtI3s0OKXLBtHTDC3T8PDAWONbMDgV8AN0Vn/y4Dzt220IuUO4ELYOTIcPnFJG3cGJK+WbL1iojUo6HEfxPwaYH9K4BfN/bG0cDwqmizdXRzYAQwLto/Fjip6Gi3ljucdx4ccEDYbtcunemc6uIRkQxpKCN1d/fptXe6+3Qz61vMm5tZS0J3Tn/gd8C/geXuHk1uZx7Qq57XjgHGAPTp06eY6gq9SbjObk67dsmvzqnELyIZ01BGamgB+fbFvLm7bwKGmlln4GFg72IDc/fbgNsAKisrvdjX1XqTfOI1S6fFf8ABut6uiGRKQ109VWZ2Xu2dZvZtQiu+aO6+nHCt3oOAzmaW+8LpDXy0Ne+1VZYtC/37t9wSttNI/Kedlq9fRCQDGmrxXwQ8bGZnkU/0lUAboNFLMJpZN2CDuy83s/bAUYSB3aeAUwkze0YD47c9/EZs2BDuc4O7Y8bA6tWxVVfQ5s3h14YGd0UkI+pN/O6+CDjYzIYDuUXs/+HuTxb53j2AsVE/fwvg7+4+wczeBu4zs+uA14E/b3v4jch1seQS/4knxlZVvcaMgccfh3nzkq9bRKSARkcd3f0pQit9q7j7m8B+Bfa/B3xxa99vm9RO/AsXhuWZBw1KpHogP51TRCQjSns9/lziz525e911cPjhycawaZNm9YhIppR24q+oCMs05Fr4mscvIlLcIm3N1q67hrVyctJYnVOJX0QyprQz0oYNYZ2cjh1D8m3XLnS9JJmMTzgBvpjMkIaISDFKu6vnhRegSxd47rmwncblF0ePhksvTa4+EZFGlHaLv/bg7nHHhZU5c9tJWL06zOHv0CG5OkVEGlDaib/2CVxDhoRbkkaNCr8wpkxJtl4RkXqUdldP7Xn8H38cun8++yy5GDS4KyIZU16J/8kn4ZBDYM6c5GJQ4heRjCntxD94MPz0p/krbqUxuKvELyIZU9oZafDgcMtJK/FryQYRyZDSTvwrVsCnn0LPniH5ppH4zzsPdtwxufpERBpR2l09f/0r9OkT1uUHaB9dPybJxP9f/wVnnZVcfSIijSjtxF97cLd/f3jgARg2LLkYFi7Mf/GIiGRAeST+3AlbnTvDqadCjx7JxXDYYXDBBcnVJyLSiPJI/LkW/7p1MGkSfPBBcjFoVo+IZExpJ/4NG6BFi/ysmhUr4Oij4dFHk4tBiV9EMqa0M9Lxx+fn8IPm8YuIUOqJ/6CDwi1HiV9EpMQT/0cfhdUxBwwI261aha6fJBP/tdfCwIHJ1Sci0ojSTvzXXgsTJsD8+WHbLPnLL373u8nVJSJShNJO/Bs25Gf05IwfH07qSsqsWdC1a7iJiGRAac/qWb++7kVXjjwy3/WThH32gZtuSq4+EZFGlH7ir93inzgRXnwxmfrdNbgrIplT2hmpUIv/4ovDip01Z/vEZfPmcK/ELyIZUtoZ6fvfh5Urt9yX5OBu7SUjREQyoLQT/8iRdfclmfhzXzodOyZTn4hIEWLr4zez3czsKTN728zeMrMLo/1dzGySmc2O7iviiqGgJBP/DjvA7bfD8OHJ1CciUoQ4B3c3Aj9090HAgcD5ZjYIuByY7O57AZOj7eQknfjPPRcGDUqmPhGRIsTW1ePuC4AF0eOVZjYT6AWMAo6InjYWeBq4LK446vjlL/ODrnFbvhzeeSckfl2FS0QyIpHpnGbWF9gPeBnoHn0pACwEuicRw3987nNbXoc3Ts8/DwccAG+/nUx9IiJFiD3xm9mOwIPARe6+omaZuzvg9bxujJlVmVnVkiVLmi6gF16Av/2t6d6vIRrcFZEMijXxm1lrQtK/x90finYvMrMeUXkPYHGh17r7be5e6e6V3bp1a7qg7r4bLrqo6d6vIUr8IpJBcc7qMeDPwEx3v7FG0SPA6OjxaGB8XDEUpOmcIlLm4pzHfwhwNjDdzKZF+64Ergf+bmbnAu8DX4sxhrrSSPwa2BWRDIlzVs8UwOopLnBmVULatQurdm7alL8kY1xOOy0MJsddj4jIVijtM3cLyV2Fa9066NAh3roGDdIcfhHJnNJenbOQc86BmTOhbdv465o6FV55Jf56RES2Qvm1+Lt1C7ckXH01LFoEVVXJ1CciUoTya/FXV4cLoyxbFn9dK1dqRo+IZE75Jf433oAf/AAWLGj8udtLiV9EMqj8En9ucDeJKZ1K/CKSQUr8cVLiF5EMKr/B3SQT/9//Dl27xl+PiMhWKL/En5vGmUTi/9KX4q9DRGQrlV9Xz9Ch8OGHMGJEvPWsXQv33Qdz5sRbj4jIViq/xN+2LfTune/yicvixXDmmfDUU/HWIyKylcov8a9YAT/7WTirNu56QIO7IpI55Zf416wJZ9S+/HK89WhJZhHJqPJL/DUXaYuTEr+IZFT5Jv64Z/Uo8YtIRpVf4m/TJtzHnfhHjICXXoL+/eOtR0RkK5XfPH6zZK7CVVEBBxwQbx0iItug/BI/wPz58V+E5dVXYfr0sP6/1XchMhGR5JVfVw+E1njcF2J58EH4zneU9EUkc8oz8f/v/8I998RbhxZoE5GMKs/Ef8cd8Mgj8daxciV06hRvHSIi26A8E3/btvEP7q5YoRa/iGRSeSb+JGb1qKtHRDKqPGf1JJH477or/rODRUS2Qfkm/uXL462jZ894319EZBuVZ+L/xz+gRcy9XLfcAkOGxL/uv4jIVirPPv6WLeOfX3/VVfDoo/HWISKyDcoz8d91F/zoR/G9vzusWqXBXRHJpNgSv5n9xcwWm9mMGvu6mNkkM5sd3VfEVX+Dnn8ebrwRBg/O36ZPD2UPPLDl/tztvfdC+dixhcsXLQrlt94KgwaF5K/ELyIZFGcf/53Ab4G/1th3OTDZ3a83s8uj7ctijKGws8+GTz4JyTmnfftwX1EREndtuSUeunQpXN4qOpRdu4a+/f32g1GjmjZuEZEmYF4z+TX1m5v1BSa4+5Bouxo4wt0XmFkP4Gl3H9jY+1RWVnpVVVVscYqIlCIzm+rulbX3J93H393dF0SPFwLdE65fRKTspTa46+GnRr0/N8xsjJlVmVnVkiVLEoxMRKS0JZ34F0VdPET3i+t7orvf5u6V7l7ZrVu3xAIUESl1SSf+R4DR0ePRwPiE6xcRKXtxTue8F3gRGGhm88zsXOB64Cgzmw0cGW2LiEiCYpvO6e5n1lM0Mq46RUSkceV55q6ISBlT4hcRKTOxnsDVVMxsCfD+Nr68K7C0CcOJg2JsGlmPMevxgWJsKlmJcXd3rzMtslkk/u1hZlWFzlzLEsXYNLIeY9bjA8XYVLIeo7p6RETKjBK/iEiZKYfEf1vaARRBMTaNrMeY9fhAMTaVTMdY8n38IiKypXJo8YuISA1K/CIiZaakE7+ZHWtm1Wb2bnTFr7Tj2c3MnjKzt83sLTO7MNqfjUtSbhlrSzN73cwmRNv9zOzl6Fjeb2ZtUo6vs5mNM7NZZjbTzA7K2nE0s4uj/+cZZnavmbVL+zhuzSVRLbglivVNMxuWYow3RP/Xb5rZw2bWuUbZFVGM1WZ2TFox1ij7oZm5mXWNtlM5jg0p2cRvZi2B3wHHAYOAM82swDUTE7UR+KG7DwIOBM6PYspdknIvYHK0nbYLgZk1tn8B3OTu/YFlwLmpRJV3M/C4u+8NfJ4Qa2aOo5n1Ar4PVEZXoGsJnEH6x/FO4Nha++o7bscBe0W3McCtKcY4CRji7vsC7wBXAESfnzOAwdFrfh999tOIETPbDTga+KDG7rSOY/3cvSRvwEHAv2psXwFckXZctWIcDxwFVAM9on09gOqU4+pNSAAjgAmAEc5CbFXo2KYQ307AHKLJCTX2Z+Y4Ar2AD4EuhMUQJwDHZOE4An2BGY0dN+CPwJmFnpd0jLXKTgbuiR5v8bkG/gUclFaMwDhCQ2Qu0DXt41jfrWRb/OQ/eDnzon2ZEF2PeD/gZbJ3ScpfAz8CNkfbOwPL3X1jtJ32sewHLAHuiLqjbjezHcjQcXT3j4BfElp+C4BPgalk6zjm1HfcsvoZ+hbwz+hxZmI0s1HAR+7+Rq2izMSYU8qJP7PMbEfgQeAid19Rs8xDkyC1ObZmdgKw2N2nphVDEVoBw4Bb3X0/YDW1unUycAh5C/AAAAOJSURBVBwrgFGEL6mewA4U6BrImrSPW2PM7MeELtN70o6lJjPrAFwJXJ12LMUo5cT/EbBbje3e0b5UmVlrQtK/x90finYXfUnKBBwCnGhmc4H7CN09NwOdzSx3/Ya0j+U8YJ67vxxtjyN8EWTpOB4JzHH3Je6+AXiIcGyzdBxz6jtumfoMmdk3gROAs6IvKMhOjHsSvuTfiD47vYHXzGxXshPjf5Ry4n8V2CuaRdGGMAD0SJoBmZkBfwZmuvuNNYoyc0lKd7/C3Xu7e1/CMXvS3c8CngJOjZ6WdowLgQ/NbGC0ayTwNhk6joQungPNrEP0/56LMTPHsYb6jtsjwDeiWSkHAp/W6BJKlJkdS+h+PNHdP6tR9Ahwhpm1NbN+hAHUV5KOz92nu/su7t43+uzMA4ZFf6uZOY7/keYAQ9w34HjCDIB/Az/OQDyHEn5GvwlMi27HE/rQJwOzgSeALmnHGsV7BDAherwH4QP1LvAA0Dbl2IYCVdGx/D+gImvHEbgWmAXMAO4C2qZ9HIF7CWMOGwjJ6dz6jhthUP930ednOmGGUloxvkvoJ899bv5Q4/k/jmKsBo5LK8Za5XPJD+6mchwbumnJBhGRMlPKXT0iIlKAEr+ISJlR4hcRKTNK/CIiZUaJX0SkzCjxi8TMzI7IrXIqkgVK/CIiZUaJXyRiZv/PzF4xs2lm9kcL1yRYZWY3RevqTzazbtFzh5rZSzXWh8+tYd/fzJ4wszfM7DUz2zN6+x0tf/2Ae6KzeUVSocQvApjZ54DTgUPcfSiwCTiLsLhalbsPBp4Brole8lfgMg/rw0+vsf8e4Hfu/nngYMLZnRBWYr2IcG2IPQjr9oikolXjTxEpCyOB/YFXo8Z4e8JiZZuB+6Pn3A08ZGY7AZ3d/Zlo/1jgATPrCPRy94cB3H0tQPR+r7j7vGh7GmEt9ynx/7NE6lLiFwkMGOvuV2yx0+wntZ63rWucrKvxeBP67EmK1NUjEkwGTjWzXeA/16HdnfAZya2m+XVgirt/Ciwzs8Oi/WcDz7j7SmCemZ0UvUfbaJ12kUxRq0MEcPe3zewqYKKZtSCsung+4SIvX4zKFhPGASAsX/yHKLG/B5wT7T8b+KOZ/TR6j9MS/GeIFEWrc4o0wMxWufuOacch0pTU1SMiUmbU4hcRKTNq8YuIlBklfhGRMqPELyJSZpT4RUTKjBK/iEiZ+f/Z61dFS56GawAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFADXIqbFs1y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}